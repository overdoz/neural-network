{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 13 - 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <span style=\"color:red\">ACHTUNG:</span> Bitte zum Starten im Menü `Cell->Run All` ausführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deaktivieren der Warnungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erträumte Bilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 13.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# IPython.display brauchen wir um die Ausgabe einer \n",
    "# Zelle zu löschen – sehr praktisch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 13.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisiere das Bild\n",
    "def deprocess(img):\n",
    "  img = 255*(img + 1.0)/2.0\n",
    "  return tf.cast(img, tf.uint8)\n",
    "\n",
    "# Bildanzeige\n",
    "def show(img):\n",
    "  plt.figure(figsize=(12,12))\n",
    "  plt.grid(False)\n",
    "  plt.axis('off')\n",
    "  plt.imshow(img)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 13.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "basedir = 'deepdream'\n",
    "original_img_file = os.path.join(basedir,'mallorca.jpg')\n",
    "\n",
    "# wir laden das Bild und verkleinern es etwas zur schnelleren Berechnung\n",
    "original_img = tf.keras.preprocessing.image.load_img(original_img_file, target_size=[375,275])\n",
    "\n",
    "original_img = np.array(original_img)\n",
    "\n",
    "show(original_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 13.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = InceptionV3(include_top=False, weights='imagenet')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 13.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ziel ist die Maximierung der Aktivierung in diesen Layern\n",
    "names = ['mixed3', 'mixed5']\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "\n",
    "# Unser Traummodell basiert auf Inception_v3\n",
    "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 13.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(img, model):\n",
    "    # Vorwärts Pass des Bilders durch das Modell um die Aktivierung zu erhalten\n",
    "    # Konvertierung des Bildes zu einer Batchgrösse 1\n",
    "    img_batch = tf.expand_dims(img, axis=0)\n",
    "    layer_activations = model(img_batch)\n",
    "    \n",
    "    losses = []\n",
    "    for act in layer_activations:\n",
    "        loss = tf.math.reduce_mean(act)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    return  tf.reduce_sum(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 13:34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def deepdream(model, img, step_size):\n",
    "    with tf.GradientTape() as tape:\n",
    "      # Gradientenberechnung in Bezug auf das Bild `img`\n",
    "      tape.watch(img)\n",
    "      loss = calculate_loss(img, model)\n",
    "\n",
    "    # Berechne den Gradienten der Loss in Bezug auf die Pixel des Eingabebildes.\n",
    "    gradients = tape.gradient(loss, img)\n",
    "\n",
    "    # Normalisierung des Gradienten.\n",
    "    gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "    \n",
    "    # Im Gradientenanstieg wird der \"Loss\" maximiert, damit das Eingabild die Layers zu Traummustern \"anregt\"\n",
    "    # Das Bild wird direkt upgedatet indem de Gradient dazuaddiert wird (haben die gleiche Dimension)\n",
    "    img = img + gradients*step_size\n",
    "    img = tf.clip_by_value(img, -1, 1)\n",
    "    return loss, img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 13.35\n",
    "Decorator-Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# das ist unsere Decorator-Funktion\n",
    "def timeit(original_fn):\n",
    "    def decorator_fn(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        res = original_fn(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print('func:%r args:[%r, %r] Ergebnis: %r Zeit: %2.6f sec' % (original_fn.__name__,\n",
    "                                                         args, kwargs, res, end - start))\n",
    " \n",
    "    return decorator_fn\n",
    " \n",
    "@timeit\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "add(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 13.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deepdream_feedback(model, img, steps=100, step_size=0.01):\n",
    "  # Konvertierung von uint8 in den Bereich das von Inception_v3 erwartet wird.\n",
    "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "\n",
    "  for step in range(steps):\n",
    "    loss, img = deepdream(model, img, step_size)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "      clear_output(wait=True)\n",
    "      show(deprocess(img))\n",
    "      print (\"Step {}, loss {}\".format(step, loss))\n",
    "\n",
    "\n",
    "  result = deprocess(img)\n",
    "  clear_output(wait=True)\n",
    "  show(result)\n",
    "\n",
    "  return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing 13.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCTAVE_SCALE = 1.3\n",
    "\n",
    "img = tf.constant(np.array(original_img))\n",
    "\n",
    "base_shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "\n",
    "for n in range(3):\n",
    "  new_shape = tf.cast(base_shape*(OCTAVE_SCALE**n), tf.int32)\n",
    "\n",
    "  img = tf.image.resize(img, new_shape).numpy()\n",
    "\n",
    "  img = run_deepdream_feedback(model=dream_model, img=img, steps=500, step_size=0.01)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
