{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x = 0.200000, Gew√ºnschter Output y = 0.20\n",
      "Iter\tx\tw\tnet i\ta\ty_hat\ty\tE\tE'\tw delta\n",
      "0\t0.2\t-10.00\t-2.00\t-2.00\t-2.00\t0.20\t2.42\t-0.54\t0.01\n",
      "10\t0.2\t -9.95\t-1.99\t-1.99\t-1.99\t0.20\t2.40\t-0.54\t0.01\n",
      "20\t0.2\t -9.89\t-1.98\t-1.98\t-1.98\t0.20\t2.37\t-0.54\t0.01\n",
      "30\t0.2\t -9.84\t-1.97\t-1.97\t-1.97\t0.20\t2.35\t-0.54\t0.01\n",
      "40\t0.2\t -9.78\t-1.96\t-1.96\t-1.96\t0.20\t2.33\t-0.53\t0.01\n",
      "50\t0.2\t -9.73\t-1.95\t-1.95\t-1.95\t0.20\t2.30\t-0.53\t0.01\n",
      "60\t0.2\t -9.68\t-1.94\t-1.94\t-1.94\t0.20\t2.28\t-0.53\t0.01\n",
      "70\t0.2\t -9.63\t-1.93\t-1.93\t-1.93\t0.20\t2.26\t-0.53\t0.01\n",
      "80\t0.2\t -9.57\t-1.91\t-1.91\t-1.91\t0.20\t2.24\t-0.52\t0.01\n",
      "90\t0.2\t -9.52\t-1.90\t-1.90\t-1.90\t0.20\t2.21\t-0.52\t0.01\n",
      "100\t0.2\t -9.47\t-1.89\t-1.89\t-1.89\t0.20\t2.19\t-0.52\t0.01\n",
      "110\t0.2\t -9.42\t-1.88\t-1.88\t-1.88\t0.20\t2.17\t-0.52\t0.01\n",
      "120\t0.2\t -9.37\t-1.87\t-1.87\t-1.87\t0.20\t2.15\t-0.51\t0.01\n",
      "130\t0.2\t -9.31\t-1.86\t-1.86\t-1.86\t0.20\t2.13\t-0.51\t0.01\n",
      "140\t0.2\t -9.26\t-1.85\t-1.85\t-1.85\t0.20\t2.11\t-0.51\t0.01\n",
      "150\t0.2\t -9.21\t-1.84\t-1.84\t-1.84\t0.20\t2.09\t-0.51\t0.01\n",
      "160\t0.2\t -9.16\t-1.83\t-1.83\t-1.83\t0.20\t2.07\t-0.50\t0.01\n",
      "170\t0.2\t -9.11\t-1.82\t-1.82\t-1.82\t0.20\t2.05\t-0.50\t0.01\n",
      "180\t0.2\t -9.06\t-1.81\t-1.81\t-1.81\t0.20\t2.02\t-0.50\t0.00\n",
      "190\t0.2\t -9.01\t-1.80\t-1.80\t-1.80\t0.20\t2.00\t-0.50\t0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def func_id(x):\n",
    "    return x\n",
    "\n",
    "def func_sigmoid(x):\n",
    "    return 1.0 / (1.0+np.exp(-x))\n",
    "\n",
    "# Initialisierungen\n",
    "x = 0.2\n",
    "y = x\n",
    "eta = 0.01\n",
    "\n",
    "# Startgewicht\n",
    "weight = -10.0\n",
    "\n",
    "# F√ºr den Plot\n",
    "weights = []\n",
    "errors = []\n",
    "w_deltas = []\n",
    "\n",
    "# Tabelle erzeugen\n",
    "print(\"Input x = {:.6f}, Gew√ºnschter Output y = {:.2f}\".format(x,y))\n",
    "print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format('Iter', 'x', 'w', 'net i', 'a', 'y_hat', 'y', 'E', \"E'\", 'w delta'))\n",
    "\n",
    "# Fixe 121 Schritte\n",
    "for step in range(200):\n",
    "    \n",
    "    # Net input berechnen\n",
    "    net_i = weight * x\n",
    "    \n",
    "    # Aktivierung (identische Funktion)\n",
    "    activation = func_id(net_i)\n",
    "    \n",
    "    # Errechneter Output\n",
    "    y_hat = activation\n",
    "    \n",
    "    # Quadratischer Fehler: Gew√ºnschter - errechneter Wert\n",
    "    error = 0.5 * (y - y_hat)**2\n",
    "    \n",
    "    # Gradient\n",
    "    derivative = (-1.0)*func_sigmoid(x)*(1.0-func_sigmoid(x))*(y - y_hat)\n",
    "    \n",
    "    # Delta f√ºr Gewichtsanpassung\n",
    "    w_delta = (-1)*derivative*eta\n",
    "    \n",
    "    # Daten f√ºr den Plot (weight, error)\n",
    "    weights.append(weight)\n",
    "    errors.append(error)\n",
    "    w_deltas.append(w_delta)\n",
    "    \n",
    "    # Ausgabe der √Ñnderung alle 10 Schritte\n",
    "    if step % 10 == 0:\n",
    "        print(\"{}\\t{}\\t{:6.2f}\\t{:5.2f}\\t{:5.2f}\\t{:5.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\".format(step, x, weight, net_i, activation, y_hat, y, error, derivative, w_delta))\n",
    "        \n",
    "    # Gewichtsanspassung = Lernen\n",
    "    weight += w_delta\n",
    "    \n",
    "# Plot erzeugen\n",
    "# Figure und Subplot\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(weights, errors, label=\"Fehler\")\n",
    "ax1.plot(weights, w_deltas, label=\"w deltas\")\n",
    "\n",
    "# Titel\n",
    "ax1.set_title('Gradient Descent')\n",
    "\n",
    "# Legende\n",
    "legend = ax1.legend(loc='best', fancybox=True, framealpha=0.5)\n",
    "\n",
    "# Raster\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Label\n",
    "plt.xlabel('Gewicht')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func_id(x):\n",
    "    return x\n",
    "\n",
    "# Aktivierungsfunktion: Sigmoide\n",
    "def func_sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# Rectified Linear Unit\n",
    "def func_relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "class MLP(object):\n",
    "    def __init__(self, n_input_neurons=2, n_hidden_neurons=2, n_output_neurons=1, weights=None, eta=0.01, n_interations=10, random_state=2, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialisierung des Netzwerks\n",
    "        Input-Hidden-Output\n",
    "        Anzahl der Neuronen ist flexibel\n",
    "        \"\"\"\n",
    "        \n",
    "        # Aktivierungs und Output-Funktion\n",
    "        self.f_akt = func_sigmoid\n",
    "        self.g_out = func_id\n",
    "        \n",
    "        # Anzahl der Neuronen pro Layer\n",
    "        self.n_input_neurons = n_input_neurons\n",
    "        self.n_hidden_neurons = n_hidden_neurons\n",
    "        self.n_output_neurons = n_output_neurons\n",
    "        \n",
    "        # Gewichtsinitialisierung\n",
    "        self.weights = weights\n",
    "        W_IH=[]\n",
    "        W_HO=[]\n",
    "        \n",
    "        # Lernrate\n",
    "        self.eta = eta\n",
    "        \n",
    "        # Iterationen\n",
    "        self.n_iterations = n_interations\n",
    "        \n",
    "        # Zufallsgenerator\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        #Erzeugung des Zufallsgenerator\n",
    "        self.random_state = check_random_state(self.random_state)\n",
    "        \n",
    "        # Fehler beim fit\n",
    "        self.erros=[]\n",
    "        \n",
    "        # Hier werden alle Daten zur Netzberechnung abgelegt\n",
    "        self.network=[]\n",
    "        \n",
    "        # Input Layer + Bias Neuron: Spalten = o_i\n",
    "        self.inputLayer = np.zeros((self.n_input_neurons+1,1))\n",
    "        \n",
    "        # Bias-Neuron Output ist immer +1\n",
    "        self.inputLayer[0] = 1.0\n",
    "        \n",
    "        # Den Input Layer zum Netzwerk hinzuf√ºgen\n",
    "        self.network.append(self.inputLayer)\n",
    "        \n",
    "        # Weights von Input Layer zum Hidden Layer W_IH\n",
    "        # Neuron: Zeile x Spalten: Zeilen = # Hidden, Spalten = # Input\n",
    "        # Nur initialisieren, falls tats√§chlich Gewichte vorhanden\n",
    "        if weights:\n",
    "            W_IH = self.weights[0]\n",
    "        else:\n",
    "            W_IH = 2 * random_state.random_sample((self.n_hidden_neurons+1, self.n_input_neurons+1)) - 1\n",
    "        self.network.append(W_IH)\n",
    "        \n",
    "        # Hidden Layer + Bias-Neuron: Spalten = net_i,a_i,o_i\n",
    "        self.hiddenLayer = np.zeros((self.n_hidden_neurons+1,5))\n",
    "        \n",
    "        # Bias-Neuron-Output ist immer +1\n",
    "        self.hiddenLayer[0] = 1.0\n",
    "        \n",
    "        # Den Hidden Layer zum Netzwerk hinzuf√ºgen\n",
    "        self.network.append(self.hiddenLayer)\n",
    "        \n",
    "        # Weights von Hidden Layer zum Output Layer W_HO\n",
    "        # Neuron: Zeile x Spalten: Zeilen = # Output, Spalten = # Hidden\n",
    "        if weights:\n",
    "            W_HO = self.weights[1]\n",
    "        else:\n",
    "            W_IH = 2 * random_state.random_sample((self.n_output_neurons+1, self.n_hidden_neurons+1)) - 1\n",
    "        self.network.append(W_HO)\n",
    "        \n",
    "        # Output-Layer + Bias-Neuron: Spalten = net_i, a_i, o_i\n",
    "        self.outputLayer = np.zeros((self.n_output_neurons+1,5))\n",
    "        \n",
    "        # Bias-Neuron Output = 0, da nicht relevant\n",
    "        # Nur wegen einheitlicher Indizierung vorhanden\n",
    "        self.outputLayer[0] = 0.0\n",
    "        \n",
    "        # Den Output-Layer zum Netzwerk hinzuf√ºgen\n",
    "        self.network.append(self.outputLayer)\n",
    "        \n",
    "    def print(self):\n",
    "        print('Multi-Layer Perceptron - Netzwerkarchitektur')\n",
    "        # Insgesamt 7 Stellen, mit drei Nachkommastellen ausgeben\n",
    "        np.set_printoptions(formatter={'float': lambda x: \"{0:7.3f}\".format(x)})\n",
    "        for nn_part in self.network:\n",
    "            print(nn_part)\n",
    "            print('----------v----------')\n",
    "            \n",
    "    def predict(self,x):\n",
    "        \"\"\"\n",
    "        F√ºr Eingabe x wird Ausgabe y_hat berechnet\n",
    "        F√ºr den Vektor x wird eine Vorhersage berechnet und \n",
    "        die Matrizenwerte der Layer (nicht Gewichte) werden angepasst\n",
    "        \"\"\"\n",
    "        \n",
    "        ##################\n",
    "        # Input Layer\n",
    "        # Die Input-Werte setzen: Alle Zeilen, Spalte 0\n",
    "        self.network[0][:,2] = x\n",
    "        \n",
    "        \n",
    "        ###################\n",
    "        # Hidden Layer\n",
    "        # Start von Zeile 1 wegen Bias-Neuron aus Indexposition 0\n",
    "        # net_i = W_ij . x\n",
    "        self.network[2][1:,0] = np.dot(self.network[1][1:,:], self.network[0][:,2])\n",
    "        \n",
    "        # a_j\n",
    "        self.network[2][1:,1] = self.f_akt(self.network[2][1:,0])\n",
    "        \n",
    "        # o_j\n",
    "        self.network[2][1:,2] = self.g_out(self.network[2][1:,1])\n",
    "        \n",
    "        # der_j = o_j*(1-o_j) Ableitung f√ºr Sigmoide\n",
    "        self.network[2][1:,3] = self.network[2][1:,2] * \\(1.0 - self.network[2][1:,2])\n",
    "        \n",
    "        \n",
    "        ###################\n",
    "        # Output-Layer\n",
    "        # Start von Zeile 1 wegen Bias-Neuron auf 0\n",
    "        # net_k = W_jk . h\n",
    "        self.network[4][1:,0] = np.dot(self.network[3][1:,:], self.network[2][:,2])\n",
    "        \n",
    "        # a_k\n",
    "        self.network[4][1:,1] = self.f_akt(self.network[4][1:,0])\n",
    "        \n",
    "        # o_k\n",
    "        self.network[4][1:,2] = self.g_out(self.network[4][1:,1])\n",
    "        \n",
    "        # der_k = o_k * (1-o_k) Ableitung f√ºr Sigmoide\n",
    "        self.network[4][1:,3] = self.network[4][1:,2] * \\(1.0 - self.network[4][1:,2])\n",
    "        \n",
    "        # R√ºckgabe Output Vektor\n",
    "        return self.network[4][1:,2]\n",
    "    \n",
    "def main():\n",
    "    # Initialisierung der Gewichte\n",
    "    W_IH = np.matrix([[0.0,0.0,0.0], [-10,20.0,20.0],[30,-20.0,-20.0]])\n",
    "    W_HO = np.matrix([[0.0,0.0,0.0], [-30, 20.0, 20.0]])\n",
    "    weights=[]\n",
    "    weights.append(W_IH)\n",
    "    weights.append(W_HO)\n",
    "    nn = MLP(weights=weights)\n",
    "    \n",
    "    # Netzwerk ausgeben\n",
    "    nn.print()\n",
    "    \n",
    "    # Test\n",
    "    X = np.array([[1.0,1.0,1.0], [1.0,0,1.0], [1.0,1.0,0], [1.0,0,0]])\n",
    "    y = np.array([0,1.0,1.0,0])\n",
    "    \n",
    "    print('Predict:')\n",
    "    for idx, x in enumerate(X):\n",
    "        print('{} {} -> {}'.format(x,y[idx],nn.predict(x)))\n",
    "        \n",
    "        \n",
    "# Et voil√†\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
